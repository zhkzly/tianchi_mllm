{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from torchvision import io\n",
    "from typing import Dict\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load the model in half-precision on the available device(s)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "\n",
    "# Image\n",
    "url = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Preprocess the inputs\n",
    "text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "# Excepted output: '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Describe this image.<|im_end|>\\n<|im_start|>assistant\\n'\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text_prompt], images=[image], padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "\n",
    "# Inference: Generation of the output\n",
    "output_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    ")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zkl/others/master/pycodes/project/competitions/tianchi/mllm/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost: 0.02s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_dataset(data_path, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1,saving=True,seed=123):\n",
    "    # 用来产生训练集、验证集、测试集的函数，输入的data_path 是一个文件夹，下面需要有一个data.json文件，里面是json格式的数据，\n",
    "    # 该函数会将之后的结果保存到和data.json同级的train.json、val.json、test.json文件中。\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    data_json_path=os.path.join(data_path, 'data.json')\n",
    "    with open(data_json_path, 'r') as f:\n",
    "        data_json=json.load(f)\n",
    "    index=np.arange(len(data_json))\n",
    "    shullfed_index=np.random.permutation(index)\n",
    "    train_index=shullfed_index[:int(len(data_json)*train_ratio)]\n",
    "    val_index=shullfed_index[int(len(data_json)*train_ratio):int(len(data_json)*(train_ratio+val_ratio))]\n",
    "    test_index=shullfed_index[int(len(data_json)*(train_ratio+val_ratio)):]\n",
    "    \n",
    "    train_json=[*map(lambda i:data_json[i],train_index)]\n",
    "    val_json=[*map(lambda i:data_json[i],val_index)]\n",
    "    test_json=[*map(lambda i:data_json[i],test_index)]\n",
    "    # train_json=[data_json[i] for i in train_index]\n",
    "    # val_json=[data_json[i] for i in val_index]\n",
    "    # test_json=[data_json[i] for i in test_index]\n",
    "    \n",
    "    if saving:\n",
    "        for json_name,json_data in zip(['train', 'val', 'test'], [train_json, val_json, test_json]):\n",
    "            with open(os.path.join(data_path, f'{json_name}.json'), 'w') as f:\n",
    "                json.dump(obj=json_data, fp=f,ensure_ascii=False)\n",
    "    return train_json, val_json, test_json\n",
    "    \n",
    "    \n",
    "\n",
    "start_time=time.time()\n",
    "train_json, val_json, test_json=split_dataset(data_path='../datas/train',train_ratio=0.8,val_ratio=0.1,test_ratio=0.1,saving=True,seed=123)\n",
    "print(f'Time cost: {time.time()-start_time:.2f}s')\n",
    "    \n",
    "# maping :0.01s-0.02s   \n",
    "# train [for ]:0.01s-0.02s\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载训练或者测试的数据的 dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python312.zip'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python3.12'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python3.12/lib-dynload'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python3.12/site-packages'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python312.zip'\u001b[0m,\n",
       "    \u001b[32m'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python3.12'\u001b[0m,\n",
       "    \u001b[32m'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python3.12/lib-dynload'\u001b[0m,\n",
       "    \u001b[32m''\u001b[0m,\n",
       "    \u001b[32m'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python3.12/site-packages'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from rich import print\n",
    "print(sys.path)\n",
    "sys.path.append('/home/zkl/others/master/pycodes/project/competitions/tianchi/mllm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(data_dict)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m images\u001b[38;5;241m=\u001b[39mdata_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 确定行数和列数以创建网格布局，这里假设最多 4 列\u001b[39;00m\n\u001b[1;32m     11\u001b[0m num_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(images)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from src.data_utils import CustomDataset,Conversions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_set=CustomDataset(data_path='../datas/train',data_type='train')\n",
    "data_dict=data_set[12]\n",
    "# print(data_dict)\n",
    "images=data_dict['image']\n",
    "\n",
    "\n",
    "# 确定行数和列数以创建网格布局，这里假设最多 4 列\n",
    "num_images = len(images)\n",
    "cols = min(num_images, 4)  # 最多4列\n",
    "rows = (num_images + cols - 1) // cols  # 计算需要多少行\n",
    "\n",
    "# 创建一个子图网格\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "axes = axes.flatten()  # 将 axes 展平为一维数组，方便迭代\n",
    "\n",
    "# 显示每个图像\n",
    "for ax, img in zip(axes, images):\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')  # 关闭坐标轴\n",
    "\n",
    "# 如果图像数量不足填满整个网格，关闭多余的子图\n",
    "for idx in range(num_images, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "conversations=Conversions()\n",
    "conversations.parse_conversation(data_dict['instruction'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen/Qwen2-VL-2B-Instruct\n",
    "from transformers import Qwen2VLModel, Qwen2VLTokenizer,Qwen2VLPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #000000; text-decoration-color: #000000\">!DOCTYPE html&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;html&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;head&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    &lt;title&gt;Welcome Page&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">title</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">head</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;body&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    &lt;h1&gt;Hello, Alice!&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">h1</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">body</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">html</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m<\u001b[0m\u001b[39m!DOCTYPE html>\u001b[0m\n",
       "\u001b[39m<html>\u001b[0m\n",
       "\u001b[39m<head>\u001b[0m\n",
       "\u001b[39m    <title>Welcome Page<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mtitle\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mhead\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39m<body>\u001b[0m\n",
       "\u001b[39m    <h1>Hello, Alice!<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mh1\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mbody\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mhtml\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jinja2 import Template\n",
    "# 定义模板字符串\n",
    "template_str = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Welcome Page</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Hello, {{ name }}!</h1>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# 创建模板对象\n",
    "template = Template(template_str)\n",
    "\n",
    "# 渲染模板，传入上下文数据\n",
    "rendered_html = template.render(name='Alice')\n",
    "\n",
    "print(rendered_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Template</span><span style=\"color: #000000; text-decoration-color: #000000\"> memory:77118f53c4a0</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mTemplate\u001b[0m\u001b[39m memory:77118f53c4a0\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "a={\n",
    "    \"chat_template\": \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}\\\n",
    "        {% for message in messages %}\\\n",
    "            {% if loop.first and message['role'] != 'system' %}\\\n",
    "                <|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n\\\n",
    "            {% endif %}\\\n",
    "            <|im_start|>{{ message['role'] }}\\n\\\n",
    "            {% if message['content'] is string %}\\\n",
    "                {{ message['content'] }}<|im_end|>\\n\\\n",
    "            {% else %}\\\n",
    "                {% for content in message['content'] %}\\\n",
    "                    {% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}\\\n",
    "                        {% set image_count.value = image_count.value + 1 %}\\\n",
    "                        {% if add_vision_id %}\\\n",
    "                            Picture {{ image_count.value }}: \\\n",
    "                        {% endif %}\\\n",
    "                        <|vision_start|><|image_pad|><|vision_end|>\\\n",
    "                        {% elif content['type'] == 'video' or 'video' in content %}\\\n",
    "                            {% set video_count.value = video_count.value + 1 %}\\\n",
    "                            {% if add_vision_id %}Video {{ video_count.value }}: \\\n",
    "                        {% endif %}\\\n",
    "                        <|vision_start|><|video_pad|><|vision_end|>\\\n",
    "                        {% elif 'text' in content %}\\\n",
    "                            {{ content['text'] }}\\\n",
    "                        {% endif %}\\\n",
    "                    {% endfor %}<|im_end|>\\n\\\n",
    "            {% endif %}\\\n",
    "        {% endfor %}\\\n",
    "        {% if add_generation_prompt %}\\\n",
    "            <|im_start|>assistant\\n\\\n",
    "        {% endif %}\"\n",
    "}\n",
    "template = Template(a['chat_template']) \n",
    "print(template)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">你是一个电商客服专家，请根据用户与客服的多轮对话判断用户的意图分类标签。\n",
       "<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">用户与客服的对话</span><span style=\"color: #000000; text-decoration-color: #000000\"> START&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">用户: 于</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">客服: 十里春风不及您，欢迎来到我们的店铺😊。我是您的小助手【客服精灵】，有什么事情是【客服精灵】能帮到您的吗？</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">用户: &lt;image&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">客服: </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">亲爱的，我在这里哦，只是一张图片还不能解答您的疑问呢，麻烦您用文字具体说明一下，比如“发货时间”、“店铺促销”等。</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">用户: 颜色变淡了吗？</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">客服: 这款皮带扣采用实心锌合金并经过真空电镀处理，颜色持久不褪，质量上乘。</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;用户与客服的对话 END</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "请直接只输出分类标签结果，不需要其他多余的话。以下是可以参考的分类标签为：<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"反馈密封性不好\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"是否好用\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"是否会生锈\"</span>\n",
       ",<span style=\"color: #008000; text-decoration-color: #008000\">\"排水方式\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"包装区别\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"发货数量\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"反馈用后症状\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"商品材质\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"功效功能\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"是否易褪色\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"适用季节\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"能否调光\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"版本款型</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">区别\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"单品推荐\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"用法用量\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"控制方式\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"上市时间\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"商品规格\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"信号情况\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"养护方法\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"套装推荐\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"何时上货\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"气泡\"</span><span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "你是一个电商客服专家，请根据用户与客服的多轮对话判断用户的意图分类标签。\n",
       "\u001b[1m<\u001b[0m\u001b[1;95m用户与客服的对话\u001b[0m\u001b[39m START>\u001b[0m\n",
       "\u001b[39m用户: 于\u001b[0m\n",
       "\u001b[39m客服: 十里春风不及您，欢迎来到我们的店铺😊。我是您的小助手【客服精灵】，有什么事情是【客服精灵】能帮到您的吗？\u001b[0m\n",
       "\u001b[39m用户: <image>\u001b[0m\n",
       "\u001b[39m客服: \u001b[0m\n",
       "\u001b[39m亲爱的，我在这里哦，只是一张图片还不能解答您的疑问呢，麻烦您用文字具体说明一下，比如“发货时间”、“店铺促销”等。\u001b[0m\n",
       "\u001b[39m用户: 颜色变淡了吗？\u001b[0m\n",
       "\u001b[39m客服: 这款皮带扣采用实心锌合金并经过真空电镀处理，颜色持久不褪，质量上乘。\u001b[0m\n",
       "\u001b[39m<用户与客服的对话 END\u001b[0m\u001b[1m>\u001b[0m\n",
       "请直接只输出分类标签结果，不需要其他多余的话。以下是可以参考的分类标签为：\u001b[1m[\u001b[0m\u001b[32m\"反馈密封性不好\"\u001b[0m,\u001b[32m\"是否好用\"\u001b[0m,\u001b[32m\"是否会生锈\"\u001b[0m\n",
       ",\u001b[32m\"排水方式\"\u001b[0m,\u001b[32m\"包装区别\"\u001b[0m,\u001b[32m\"发货数量\"\u001b[0m,\u001b[32m\"反馈用后症状\"\u001b[0m,\u001b[32m\"商品材质\"\u001b[0m,\u001b[32m\"功效功能\"\u001b[0m,\u001b[32m\"是否易褪色\"\u001b[0m,\u001b[32m\"适用季节\"\u001b[0m,\u001b[32m\"能否调光\"\u001b[0m,\u001b[32m\"版本款型\u001b[0m\n",
       "\u001b[32m区别\"\u001b[0m,\u001b[32m\"单品推荐\"\u001b[0m,\u001b[32m\"用法用量\"\u001b[0m,\u001b[32m\"控制方式\"\u001b[0m,\u001b[32m\"上市时间\"\u001b[0m,\u001b[32m\"商品规格\"\u001b[0m,\u001b[32m\"信号情况\"\u001b[0m,\u001b[32m\"养护方法\"\u001b[0m,\u001b[32m\"套装推荐\"\u001b[0m,\u001b[32m\"何时上货\"\u001b[0m,\u001b[32m\"气泡\"\u001b[0m\u001b[1m]\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=\"你是一个电商客服专家，请根据用户与客服的多轮对话判断用户的意图分类标签。\\n<用户与客服的对话 START>\\n用户: 于\\n客服: 十里春风不及您，欢迎来到我们的店铺😊。我是您的小助手【客服精灵】，有什么事情是【客服精灵】能帮到您的吗？\\n用户: <image>\\n客服: 亲爱的，我在这里哦，只是一张图片还不能解答您的疑问呢，麻烦您用文字具体说明一下，比如“发货时间”、“店铺促销”等。\\n用户: 颜色变淡了吗？\\n客服: 这款皮带扣采用实心锌合金并经过真空电镀处理，颜色持久不褪，质量上乘。\\n<用户与客服的对话 END>\\n请直接只输出分类标签结果，不需要其他多余的话。以下是可以参考的分类标签为：[\\\"反馈密封性不好\\\",\\\"是否好用\\\",\\\"是否会生锈\\\",\\\"排水方式\\\",\\\"包装区别\\\",\\\"发货数量\\\",\\\"反馈用后症状\\\",\\\"商品材质\\\",\\\"功效功能\\\",\\\"是否易褪色\\\",\\\"适用季节\\\",\\\"能否调光\\\",\\\"版本款型区别\\\",\\\"单品推荐\\\",\\\"用法用量\\\",\\\"控制方式\\\",\\\"上市时间\\\",\\\"商品规格\\\",\\\"信号情况\\\",\\\"养护方法\\\",\\\"套装推荐\\\",\\\"何时上货\\\",\\\"气泡\\\"]\\n\"\n",
    "\n",
    "\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from torchvision import io\n",
    "from typing import Dict\n",
    "import os\n",
    "os.environ['HF_HOME']='huggingface'\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from data_utils import CustomDataset,Conversions\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def main():\n",
    "    # Load the model in half-precision on the available device(s)\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        \"Qwen/Qwen2-VL-2B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    "    )\n",
    "    processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "    \n",
    "    data_set=CustomDataset(data_path='datas/train',data_type='train')\n",
    "    i=0\n",
    "    datas={'instruction':[],'image':[]}\n",
    "    while i<=100:\n",
    "        if len(data_set[i]['image'])==1:\n",
    "            datas['instruction'].append(data_set[i]['instruction'])\n",
    "            datas['image'].append(data_set[i]['image'][0])\n",
    "            i+=1\n",
    "            continue\n",
    "    conversation_helper=Conversions()\n",
    "    def resize_image(image):\n",
    "        origin_w,origin_h = image.size\n",
    "        new_w,new_h = origin_h//2,origin_w//2\n",
    "        image=image.resize((new_w,new_h))\n",
    "        return image\n",
    "    datas['image']=[resize_image(Image.open(image)) for image in datas['image']]\n",
    "    \n",
    "    conversation=[conversation_helper.parse_conversation(instruction) for instruction in datas['instruction']]\n",
    "\n",
    "    # Preprocess the inputs\n",
    "    text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "    # Excepted output: '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Describe this image.<|im_end|>\\n<|im_start|>assistant\\n'\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text_prompt], images=[datas['image']], padding=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    for input in inputs:\n",
    "        input = input.to(\"cuda\")\n",
    "\n",
    "    # Inference: Generation of the output\n",
    "    output_ids = model.generate(**input, max_new_tokens=128)\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids) :]\n",
    "        for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "    print(output_text)\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
