{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from torchvision import io\n",
    "from typing import Dict\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load the model in half-precision on the available device(s)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "\n",
    "# Image\n",
    "url = \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Preprocess the inputs\n",
    "text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "# Excepted output: '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Describe this image.<|im_end|>\\n<|im_start|>assistant\\n'\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text_prompt], images=[image], padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "\n",
    "# Inference: Generation of the output\n",
    "output_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    ")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zkl/others/master/pycodes/project/competitions/tianchi/mllm/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost: 0.02s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_dataset(data_path, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1,saving=True,seed=123):\n",
    "    # ç”¨æ¥äº§ç”Ÿè®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†çš„å‡½æ•°ï¼Œè¾“å…¥çš„data_path æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œä¸‹é¢éœ€è¦æœ‰ä¸€ä¸ªdata.jsonæ–‡ä»¶ï¼Œé‡Œé¢æ˜¯jsonæ ¼å¼çš„æ•°æ®ï¼Œ\n",
    "    # è¯¥å‡½æ•°ä¼šå°†ä¹‹åçš„ç»“æœä¿å­˜åˆ°å’Œdata.jsonåŒçº§çš„train.jsonã€val.jsonã€test.jsonæ–‡ä»¶ä¸­ã€‚\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    data_json_path=os.path.join(data_path, 'data.json')\n",
    "    with open(data_json_path, 'r') as f:\n",
    "        data_json=json.load(f)\n",
    "    index=np.arange(len(data_json))\n",
    "    shullfed_index=np.random.permutation(index)\n",
    "    train_index=shullfed_index[:int(len(data_json)*train_ratio)]\n",
    "    val_index=shullfed_index[int(len(data_json)*train_ratio):int(len(data_json)*(train_ratio+val_ratio))]\n",
    "    test_index=shullfed_index[int(len(data_json)*(train_ratio+val_ratio)):]\n",
    "    \n",
    "    train_json=[*map(lambda i:data_json[i],train_index)]\n",
    "    val_json=[*map(lambda i:data_json[i],val_index)]\n",
    "    test_json=[*map(lambda i:data_json[i],test_index)]\n",
    "    # train_json=[data_json[i] for i in train_index]\n",
    "    # val_json=[data_json[i] for i in val_index]\n",
    "    # test_json=[data_json[i] for i in test_index]\n",
    "    \n",
    "    if saving:\n",
    "        for json_name,json_data in zip(['train', 'val', 'test'], [train_json, val_json, test_json]):\n",
    "            with open(os.path.join(data_path, f'{json_name}.json'), 'w') as f:\n",
    "                json.dump(obj=json_data, fp=f,ensure_ascii=False)\n",
    "    return train_json, val_json, test_json\n",
    "    \n",
    "    \n",
    "\n",
    "start_time=time.time()\n",
    "train_json, val_json, test_json=split_dataset(data_path='../datas/train',train_ratio=0.8,val_ratio=0.1,test_ratio=0.1,saving=True,seed=123)\n",
    "print(f'Time cost: {time.time()-start_time:.2f}s')\n",
    "    \n",
    "# maping :0.01s-0.02s   \n",
    "# train [for ]:0.01s-0.02s\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŠ è½½è®­ç»ƒæˆ–è€…æµ‹è¯•çš„æ•°æ®çš„ dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python312.zip'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python3.12'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python3.12/lib-dynload'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python3.12/site-packages'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python312.zip'\u001b[0m,\n",
       "    \u001b[32m'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python3.12'\u001b[0m,\n",
       "    \u001b[32m'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python3.12/lib-dynload'\u001b[0m,\n",
       "    \u001b[32m''\u001b[0m,\n",
       "    \u001b[32m'/home/zkl/ssd/softwares/miniconda3/miniconda/envs/pythonAI/lib/python3.12/site-packages'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from rich import print\n",
    "print(sys.path)\n",
    "sys.path.append('/home/zkl/others/master/pycodes/project/competitions/tianchi/mllm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(data_dict)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m images\u001b[38;5;241m=\u001b[39mdata_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# ç¡®å®šè¡Œæ•°å’Œåˆ—æ•°ä»¥åˆ›å»ºç½‘æ ¼å¸ƒå±€ï¼Œè¿™é‡Œå‡è®¾æœ€å¤š 4 åˆ—\u001b[39;00m\n\u001b[1;32m     11\u001b[0m num_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(images)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from src.data_utils import CustomDataset,Conversions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_set=CustomDataset(data_path='../datas/train',data_type='train')\n",
    "data_dict=data_set[12]\n",
    "# print(data_dict)\n",
    "images=data_dict['image']\n",
    "\n",
    "\n",
    "# ç¡®å®šè¡Œæ•°å’Œåˆ—æ•°ä»¥åˆ›å»ºç½‘æ ¼å¸ƒå±€ï¼Œè¿™é‡Œå‡è®¾æœ€å¤š 4 åˆ—\n",
    "num_images = len(images)\n",
    "cols = min(num_images, 4)  # æœ€å¤š4åˆ—\n",
    "rows = (num_images + cols - 1) // cols  # è®¡ç®—éœ€è¦å¤šå°‘è¡Œ\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªå­å›¾ç½‘æ ¼\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "axes = axes.flatten()  # å°† axes å±•å¹³ä¸ºä¸€ç»´æ•°ç»„ï¼Œæ–¹ä¾¿è¿­ä»£\n",
    "\n",
    "# æ˜¾ç¤ºæ¯ä¸ªå›¾åƒ\n",
    "for ax, img in zip(axes, images):\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')  # å…³é—­åæ ‡è½´\n",
    "\n",
    "# å¦‚æœå›¾åƒæ•°é‡ä¸è¶³å¡«æ»¡æ•´ä¸ªç½‘æ ¼ï¼Œå…³é—­å¤šä½™çš„å­å›¾\n",
    "for idx in range(num_images, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "conversations=Conversions()\n",
    "conversations.parse_conversation(data_dict['instruction'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen/Qwen2-VL-2B-Instruct\n",
    "from transformers import Qwen2VLModel, Qwen2VLTokenizer,Qwen2VLPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #000000; text-decoration-color: #000000\">!DOCTYPE html&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;html&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;head&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    &lt;title&gt;Welcome Page&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">title</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">head</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;body&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    &lt;h1&gt;Hello, Alice!&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">h1</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">body</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">html</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m<\u001b[0m\u001b[39m!DOCTYPE html>\u001b[0m\n",
       "\u001b[39m<html>\u001b[0m\n",
       "\u001b[39m<head>\u001b[0m\n",
       "\u001b[39m    <title>Welcome Page<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mtitle\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mhead\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39m<body>\u001b[0m\n",
       "\u001b[39m    <h1>Hello, Alice!<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mh1\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mbody\u001b[0m\u001b[39m>\u001b[0m\n",
       "\u001b[39m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mhtml\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jinja2 import Template\n",
    "# å®šä¹‰æ¨¡æ¿å­—ç¬¦ä¸²\n",
    "template_str = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Welcome Page</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Hello, {{ name }}!</h1>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# åˆ›å»ºæ¨¡æ¿å¯¹è±¡\n",
    "template = Template(template_str)\n",
    "\n",
    "# æ¸²æŸ“æ¨¡æ¿ï¼Œä¼ å…¥ä¸Šä¸‹æ–‡æ•°æ®\n",
    "rendered_html = template.render(name='Alice')\n",
    "\n",
    "print(rendered_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">Template</span><span style=\"color: #000000; text-decoration-color: #000000\"> memory:77118f53c4a0</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mTemplate\u001b[0m\u001b[39m memory:77118f53c4a0\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "a={\n",
    "    \"chat_template\": \"{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}\\\n",
    "        {% for message in messages %}\\\n",
    "            {% if loop.first and message['role'] != 'system' %}\\\n",
    "                <|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n\\\n",
    "            {% endif %}\\\n",
    "            <|im_start|>{{ message['role'] }}\\n\\\n",
    "            {% if message['content'] is string %}\\\n",
    "                {{ message['content'] }}<|im_end|>\\n\\\n",
    "            {% else %}\\\n",
    "                {% for content in message['content'] %}\\\n",
    "                    {% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}\\\n",
    "                        {% set image_count.value = image_count.value + 1 %}\\\n",
    "                        {% if add_vision_id %}\\\n",
    "                            Picture {{ image_count.value }}: \\\n",
    "                        {% endif %}\\\n",
    "                        <|vision_start|><|image_pad|><|vision_end|>\\\n",
    "                        {% elif content['type'] == 'video' or 'video' in content %}\\\n",
    "                            {% set video_count.value = video_count.value + 1 %}\\\n",
    "                            {% if add_vision_id %}Video {{ video_count.value }}: \\\n",
    "                        {% endif %}\\\n",
    "                        <|vision_start|><|video_pad|><|vision_end|>\\\n",
    "                        {% elif 'text' in content %}\\\n",
    "                            {{ content['text'] }}\\\n",
    "                        {% endif %}\\\n",
    "                    {% endfor %}<|im_end|>\\n\\\n",
    "            {% endif %}\\\n",
    "        {% endfor %}\\\n",
    "        {% if add_generation_prompt %}\\\n",
    "            <|im_start|>assistant\\n\\\n",
    "        {% endif %}\"\n",
    "}\n",
    "template = Template(a['chat_template']) \n",
    "print(template)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ä½ æ˜¯ä¸€ä¸ªç”µå•†å®¢æœä¸“å®¶ï¼Œè¯·æ ¹æ®ç”¨æˆ·ä¸å®¢æœçš„å¤šè½®å¯¹è¯åˆ¤æ–­ç”¨æˆ·çš„æ„å›¾åˆ†ç±»æ ‡ç­¾ã€‚\n",
       "<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ç”¨æˆ·ä¸å®¢æœçš„å¯¹è¯</span><span style=\"color: #000000; text-decoration-color: #000000\"> START&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">ç”¨æˆ·: äº</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">å®¢æœ: åé‡Œæ˜¥é£ä¸åŠæ‚¨ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„åº—é“ºğŸ˜Šã€‚æˆ‘æ˜¯æ‚¨çš„å°åŠ©æ‰‹ã€å®¢æœç²¾çµã€‘ï¼Œæœ‰ä»€ä¹ˆäº‹æƒ…æ˜¯ã€å®¢æœç²¾çµã€‘èƒ½å¸®åˆ°æ‚¨çš„å—ï¼Ÿ</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">ç”¨æˆ·: &lt;image&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">å®¢æœ: </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">äº²çˆ±çš„ï¼Œæˆ‘åœ¨è¿™é‡Œå“¦ï¼Œåªæ˜¯ä¸€å¼ å›¾ç‰‡è¿˜ä¸èƒ½è§£ç­”æ‚¨çš„ç–‘é—®å‘¢ï¼Œéº»çƒ¦æ‚¨ç”¨æ–‡å­—å…·ä½“è¯´æ˜ä¸€ä¸‹ï¼Œæ¯”å¦‚â€œå‘è´§æ—¶é—´â€ã€â€œåº—é“ºä¿ƒé”€â€ç­‰ã€‚</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">ç”¨æˆ·: é¢œè‰²å˜æ·¡äº†å—ï¼Ÿ</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">å®¢æœ: è¿™æ¬¾çš®å¸¦æ‰£é‡‡ç”¨å®å¿ƒé”Œåˆé‡‘å¹¶ç»è¿‡çœŸç©ºç”µé•€å¤„ç†ï¼Œé¢œè‰²æŒä¹…ä¸è¤ªï¼Œè´¨é‡ä¸Šä¹˜ã€‚</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;ç”¨æˆ·ä¸å®¢æœçš„å¯¹è¯ END</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "è¯·ç›´æ¥åªè¾“å‡ºåˆ†ç±»æ ‡ç­¾ç»“æœï¼Œä¸éœ€è¦å…¶ä»–å¤šä½™çš„è¯ã€‚ä»¥ä¸‹æ˜¯å¯ä»¥å‚è€ƒçš„åˆ†ç±»æ ‡ç­¾ä¸ºï¼š<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"åé¦ˆå¯†å°æ€§ä¸å¥½\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"æ˜¯å¦å¥½ç”¨\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"æ˜¯å¦ä¼šç”Ÿé”ˆ\"</span>\n",
       ",<span style=\"color: #008000; text-decoration-color: #008000\">\"æ’æ°´æ–¹å¼\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"åŒ…è£…åŒºåˆ«\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"å‘è´§æ•°é‡\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"åé¦ˆç”¨åç—‡çŠ¶\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"å•†å“æè´¨\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"åŠŸæ•ˆåŠŸèƒ½\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"æ˜¯å¦æ˜“è¤ªè‰²\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"é€‚ç”¨å­£èŠ‚\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"èƒ½å¦è°ƒå…‰\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"ç‰ˆæœ¬æ¬¾å‹</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">åŒºåˆ«\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"å•å“æ¨è\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"ç”¨æ³•ç”¨é‡\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"æ§åˆ¶æ–¹å¼\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"ä¸Šå¸‚æ—¶é—´\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"å•†å“è§„æ ¼\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"ä¿¡å·æƒ…å†µ\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"å…»æŠ¤æ–¹æ³•\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"å¥—è£…æ¨è\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"ä½•æ—¶ä¸Šè´§\"</span>,<span style=\"color: #008000; text-decoration-color: #008000\">\"æ°”æ³¡\"</span><span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ä½ æ˜¯ä¸€ä¸ªç”µå•†å®¢æœä¸“å®¶ï¼Œè¯·æ ¹æ®ç”¨æˆ·ä¸å®¢æœçš„å¤šè½®å¯¹è¯åˆ¤æ–­ç”¨æˆ·çš„æ„å›¾åˆ†ç±»æ ‡ç­¾ã€‚\n",
       "\u001b[1m<\u001b[0m\u001b[1;95mç”¨æˆ·ä¸å®¢æœçš„å¯¹è¯\u001b[0m\u001b[39m START>\u001b[0m\n",
       "\u001b[39mç”¨æˆ·: äº\u001b[0m\n",
       "\u001b[39må®¢æœ: åé‡Œæ˜¥é£ä¸åŠæ‚¨ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„åº—é“ºğŸ˜Šã€‚æˆ‘æ˜¯æ‚¨çš„å°åŠ©æ‰‹ã€å®¢æœç²¾çµã€‘ï¼Œæœ‰ä»€ä¹ˆäº‹æƒ…æ˜¯ã€å®¢æœç²¾çµã€‘èƒ½å¸®åˆ°æ‚¨çš„å—ï¼Ÿ\u001b[0m\n",
       "\u001b[39mç”¨æˆ·: <image>\u001b[0m\n",
       "\u001b[39må®¢æœ: \u001b[0m\n",
       "\u001b[39mäº²çˆ±çš„ï¼Œæˆ‘åœ¨è¿™é‡Œå“¦ï¼Œåªæ˜¯ä¸€å¼ å›¾ç‰‡è¿˜ä¸èƒ½è§£ç­”æ‚¨çš„ç–‘é—®å‘¢ï¼Œéº»çƒ¦æ‚¨ç”¨æ–‡å­—å…·ä½“è¯´æ˜ä¸€ä¸‹ï¼Œæ¯”å¦‚â€œå‘è´§æ—¶é—´â€ã€â€œåº—é“ºä¿ƒé”€â€ç­‰ã€‚\u001b[0m\n",
       "\u001b[39mç”¨æˆ·: é¢œè‰²å˜æ·¡äº†å—ï¼Ÿ\u001b[0m\n",
       "\u001b[39må®¢æœ: è¿™æ¬¾çš®å¸¦æ‰£é‡‡ç”¨å®å¿ƒé”Œåˆé‡‘å¹¶ç»è¿‡çœŸç©ºç”µé•€å¤„ç†ï¼Œé¢œè‰²æŒä¹…ä¸è¤ªï¼Œè´¨é‡ä¸Šä¹˜ã€‚\u001b[0m\n",
       "\u001b[39m<ç”¨æˆ·ä¸å®¢æœçš„å¯¹è¯ END\u001b[0m\u001b[1m>\u001b[0m\n",
       "è¯·ç›´æ¥åªè¾“å‡ºåˆ†ç±»æ ‡ç­¾ç»“æœï¼Œä¸éœ€è¦å…¶ä»–å¤šä½™çš„è¯ã€‚ä»¥ä¸‹æ˜¯å¯ä»¥å‚è€ƒçš„åˆ†ç±»æ ‡ç­¾ä¸ºï¼š\u001b[1m[\u001b[0m\u001b[32m\"åé¦ˆå¯†å°æ€§ä¸å¥½\"\u001b[0m,\u001b[32m\"æ˜¯å¦å¥½ç”¨\"\u001b[0m,\u001b[32m\"æ˜¯å¦ä¼šç”Ÿé”ˆ\"\u001b[0m\n",
       ",\u001b[32m\"æ’æ°´æ–¹å¼\"\u001b[0m,\u001b[32m\"åŒ…è£…åŒºåˆ«\"\u001b[0m,\u001b[32m\"å‘è´§æ•°é‡\"\u001b[0m,\u001b[32m\"åé¦ˆç”¨åç—‡çŠ¶\"\u001b[0m,\u001b[32m\"å•†å“æè´¨\"\u001b[0m,\u001b[32m\"åŠŸæ•ˆåŠŸèƒ½\"\u001b[0m,\u001b[32m\"æ˜¯å¦æ˜“è¤ªè‰²\"\u001b[0m,\u001b[32m\"é€‚ç”¨å­£èŠ‚\"\u001b[0m,\u001b[32m\"èƒ½å¦è°ƒå…‰\"\u001b[0m,\u001b[32m\"ç‰ˆæœ¬æ¬¾å‹\u001b[0m\n",
       "\u001b[32måŒºåˆ«\"\u001b[0m,\u001b[32m\"å•å“æ¨è\"\u001b[0m,\u001b[32m\"ç”¨æ³•ç”¨é‡\"\u001b[0m,\u001b[32m\"æ§åˆ¶æ–¹å¼\"\u001b[0m,\u001b[32m\"ä¸Šå¸‚æ—¶é—´\"\u001b[0m,\u001b[32m\"å•†å“è§„æ ¼\"\u001b[0m,\u001b[32m\"ä¿¡å·æƒ…å†µ\"\u001b[0m,\u001b[32m\"å…»æŠ¤æ–¹æ³•\"\u001b[0m,\u001b[32m\"å¥—è£…æ¨è\"\u001b[0m,\u001b[32m\"ä½•æ—¶ä¸Šè´§\"\u001b[0m,\u001b[32m\"æ°”æ³¡\"\u001b[0m\u001b[1m]\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=\"ä½ æ˜¯ä¸€ä¸ªç”µå•†å®¢æœä¸“å®¶ï¼Œè¯·æ ¹æ®ç”¨æˆ·ä¸å®¢æœçš„å¤šè½®å¯¹è¯åˆ¤æ–­ç”¨æˆ·çš„æ„å›¾åˆ†ç±»æ ‡ç­¾ã€‚\\n<ç”¨æˆ·ä¸å®¢æœçš„å¯¹è¯ START>\\nç”¨æˆ·: äº\\nå®¢æœ: åé‡Œæ˜¥é£ä¸åŠæ‚¨ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„åº—é“ºğŸ˜Šã€‚æˆ‘æ˜¯æ‚¨çš„å°åŠ©æ‰‹ã€å®¢æœç²¾çµã€‘ï¼Œæœ‰ä»€ä¹ˆäº‹æƒ…æ˜¯ã€å®¢æœç²¾çµã€‘èƒ½å¸®åˆ°æ‚¨çš„å—ï¼Ÿ\\nç”¨æˆ·: <image>\\nå®¢æœ: äº²çˆ±çš„ï¼Œæˆ‘åœ¨è¿™é‡Œå“¦ï¼Œåªæ˜¯ä¸€å¼ å›¾ç‰‡è¿˜ä¸èƒ½è§£ç­”æ‚¨çš„ç–‘é—®å‘¢ï¼Œéº»çƒ¦æ‚¨ç”¨æ–‡å­—å…·ä½“è¯´æ˜ä¸€ä¸‹ï¼Œæ¯”å¦‚â€œå‘è´§æ—¶é—´â€ã€â€œåº—é“ºä¿ƒé”€â€ç­‰ã€‚\\nç”¨æˆ·: é¢œè‰²å˜æ·¡äº†å—ï¼Ÿ\\nå®¢æœ: è¿™æ¬¾çš®å¸¦æ‰£é‡‡ç”¨å®å¿ƒé”Œåˆé‡‘å¹¶ç»è¿‡çœŸç©ºç”µé•€å¤„ç†ï¼Œé¢œè‰²æŒä¹…ä¸è¤ªï¼Œè´¨é‡ä¸Šä¹˜ã€‚\\n<ç”¨æˆ·ä¸å®¢æœçš„å¯¹è¯ END>\\nè¯·ç›´æ¥åªè¾“å‡ºåˆ†ç±»æ ‡ç­¾ç»“æœï¼Œä¸éœ€è¦å…¶ä»–å¤šä½™çš„è¯ã€‚ä»¥ä¸‹æ˜¯å¯ä»¥å‚è€ƒçš„åˆ†ç±»æ ‡ç­¾ä¸ºï¼š[\\\"åé¦ˆå¯†å°æ€§ä¸å¥½\\\",\\\"æ˜¯å¦å¥½ç”¨\\\",\\\"æ˜¯å¦ä¼šç”Ÿé”ˆ\\\",\\\"æ’æ°´æ–¹å¼\\\",\\\"åŒ…è£…åŒºåˆ«\\\",\\\"å‘è´§æ•°é‡\\\",\\\"åé¦ˆç”¨åç—‡çŠ¶\\\",\\\"å•†å“æè´¨\\\",\\\"åŠŸæ•ˆåŠŸèƒ½\\\",\\\"æ˜¯å¦æ˜“è¤ªè‰²\\\",\\\"é€‚ç”¨å­£èŠ‚\\\",\\\"èƒ½å¦è°ƒå…‰\\\",\\\"ç‰ˆæœ¬æ¬¾å‹åŒºåˆ«\\\",\\\"å•å“æ¨è\\\",\\\"ç”¨æ³•ç”¨é‡\\\",\\\"æ§åˆ¶æ–¹å¼\\\",\\\"ä¸Šå¸‚æ—¶é—´\\\",\\\"å•†å“è§„æ ¼\\\",\\\"ä¿¡å·æƒ…å†µ\\\",\\\"å…»æŠ¤æ–¹æ³•\\\",\\\"å¥—è£…æ¨è\\\",\\\"ä½•æ—¶ä¸Šè´§\\\",\\\"æ°”æ³¡\\\"]\\n\"\n",
    "\n",
    "\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from torchvision import io\n",
    "from typing import Dict\n",
    "import os\n",
    "os.environ['HF_HOME']='huggingface'\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from data_utils import CustomDataset,Conversions\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def main():\n",
    "    # Load the model in half-precision on the available device(s)\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        \"Qwen/Qwen2-VL-2B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    "    )\n",
    "    processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "    \n",
    "    data_set=CustomDataset(data_path='datas/train',data_type='train')\n",
    "    i=0\n",
    "    datas={'instruction':[],'image':[]}\n",
    "    while i<=100:\n",
    "        if len(data_set[i]['image'])==1:\n",
    "            datas['instruction'].append(data_set[i]['instruction'])\n",
    "            datas['image'].append(data_set[i]['image'][0])\n",
    "            i+=1\n",
    "            continue\n",
    "    conversation_helper=Conversions()\n",
    "    def resize_image(image):\n",
    "        origin_w,origin_h = image.size\n",
    "        new_w,new_h = origin_h//2,origin_w//2\n",
    "        image=image.resize((new_w,new_h))\n",
    "        return image\n",
    "    datas['image']=[resize_image(Image.open(image)) for image in datas['image']]\n",
    "    \n",
    "    conversation=[conversation_helper.parse_conversation(instruction) for instruction in datas['instruction']]\n",
    "\n",
    "    # Preprocess the inputs\n",
    "    text_prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "    # Excepted output: '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>Describe this image.<|im_end|>\\n<|im_start|>assistant\\n'\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text_prompt], images=[datas['image']], padding=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    for input in inputs:\n",
    "        input = input.to(\"cuda\")\n",
    "\n",
    "    # Inference: Generation of the output\n",
    "    output_ids = model.generate(**input, max_new_tokens=128)\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids) :]\n",
    "        for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "    print(output_text)\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
